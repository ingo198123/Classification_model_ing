{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded dataset to examine its contents\n",
    "\n",
    "file_path = 'C:/Users/h_ing/Documents/GitHub/ML_classification_model/teleCust1000t.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>retire</th>\n",
       "      <th>gender</th>\n",
       "      <th>reside</th>\n",
       "      <th>custcat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region  tenure  age  marital  address  income  ed  employ  retire  gender  \\\n",
       "0       2      13   44        1        9    64.0   4       5     0.0       0   \n",
       "1       3      11   33        1        7   136.0   5       5     0.0       0   \n",
       "2       3      68   52        1       24   116.0   1      29     0.0       1   \n",
       "3       2      33   33        0       12    33.0   2       0     0.0       1   \n",
       "4       2      23   30        1        9    30.0   1       2     0.0       0   \n",
       "\n",
       "   reside  custcat  \n",
       "0       2        1  \n",
       "1       6        4  \n",
       "2       2        3  \n",
       "3       1        1  \n",
       "4       4        3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual Inspection\n",
    "Boxplot\n",
    "A boxplot provides a visual representation of outliers. Outliers typically fall beyond the whiskers of the boxplot (1.5 times the interquartile range)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Visual Inspection\n",
    "\n",
    "Boxplot\n",
    "\n",
    "A boxplot provides a visual representation of outliers. Outliers typically fall beyond the whiskers of the boxplot (1.5 times the interquartile range)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Replace 'column_name' with your actual column\n",
    "plt.boxplot(data['income'])\n",
    "plt.title(\"Boxplot of Income\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter Plot\n",
    "For relationships between two features, use a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data['age'], data['income'])\n",
    "plt.title(\"Scatter Plot of Age vs Income\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Income\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Statistical Methods for Outlier Detection\n",
    "\n",
    "- Z-Score\n",
    "\n",
    "The Z-score method identifies outliers based on how far they are from the mean in terms of standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     region  tenure  age  marital  address  income  ed  employ  retire  \\\n",
      "63        2      69   51        1       11   438.0   4      23     0.0   \n",
      "199       3      72   66        0       30   460.0   4      41     0.0   \n",
      "208       3      72   64        0       41   674.0   4      37     0.0   \n",
      "350       3      71   60        1       39   508.0   4      35     0.0   \n",
      "401       1      41   52        0       26   928.0   3      29     0.0   \n",
      "409       2      39   59        0       20  1668.0   4      27     0.0   \n",
      "613       3      68   52        1        8   456.0   3      30     0.0   \n",
      "680       1      65   59        0       27   732.0   3      31     0.0   \n",
      "799       1      66   54        1        8   591.0   4      25     0.0   \n",
      "825       2      59   49        0       28   429.0   4      23     0.0   \n",
      "849       3      65   56        1       19   608.0   3      34     0.0   \n",
      "892       2      54   55        0        1   587.0   3      33     0.0   \n",
      "917       3      70   68        0       21  1131.0   2      45     0.0   \n",
      "930       2      39   44        1       14   418.0   4      18     0.0   \n",
      "997       3      67   59        0       40   944.0   5      33     0.0   \n",
      "\n",
      "     gender  reside  custcat  \n",
      "63        1       2        4  \n",
      "199       1       1        4  \n",
      "208       1       1        3  \n",
      "350       0       4        4  \n",
      "401       0       3        3  \n",
      "409       1       1        2  \n",
      "613       1       4        3  \n",
      "680       1       1        2  \n",
      "799       1       2        4  \n",
      "825       1       2        4  \n",
      "849       1       2        4  \n",
      "892       0       1        3  \n",
      "917       0       1        3  \n",
      "930       0       2        4  \n",
      "997       1       1        4  \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = zscore(data[['income', 'age']])  # Add relevant numerical features\n",
    "outliers = (z_scores > 3).any(axis=1)  # Z-score threshold: 3\n",
    "print(data[outliers])  # View rows with outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interquartile Range (IQR)\n",
    "- The IQR method identifies outliers as values below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mahalanobis Distance\n",
    "For multivariate outliers, use Mahalanobis Distance, which measures the distance of a point from the center of the data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Whether to Remove Outliers\n",
    "\n",
    "## Should Remove Outliers:\n",
    "- When they are errors or data entry mistakes.\n",
    "- If they skew the distribution and negatively impact model performance (e.g., linear regression).\n",
    "\n",
    "## Should Keep Outliers:\n",
    "- If they are valid extreme cases (e.g., high-income customers).\n",
    "- If they carry important domain-specific insights.\n",
    "\n",
    "## Test Model Performance With and Without Outliers\n",
    "Train your model both with and without outliers to see if they harm the accuracy, precision, or recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Outliers\n",
    "- Remove Outliers\n",
    "\n",
    "If you decide to remove them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Understand the Dataset**\n",
    "\n",
    "- Review your dataset's structure and content.\n",
    "- Identify the types of features (numerical, categorical, temporal, etc.).\n",
    "- Check for correlations, trends, and patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Common Feature Engineering Techniques**\n",
    "\n",
    "Below are general techniques you can consider based on the type of data in your dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features**\n",
    "\n",
    "1. **Interaction Features:**\n",
    "    - Create new features by combining existing numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     region    tenure       age  marital   address    income  ed    employ  \\\n",
      "998       3  1.632140  0.642478        0  0.683594  0.962918   2  1.307442   \n",
      "891       3  1.115914 -1.229486        1 -0.837063 -0.379394   4 -1.116049   \n",
      "626       2 -0.902059 -1.148096        0 -0.634309 -0.379394   4 -1.000644   \n",
      "273       2  0.599688  1.130817        0  2.001496 -0.817104   1 -1.116049   \n",
      "220       1 -1.277496 -0.903927        0 -1.039817 -0.583659   2 -0.192814   \n",
      "\n",
      "     retire  gender  reside  income_employ_ratio  \n",
      "998     0.0       1       1            -0.605730  \n",
      "891     0.0       1       3             2.925132  \n",
      "626     0.0       1       1             1.481871  \n",
      "273     0.0       0       1             1.341065  \n",
      "220     0.0       1       1            -0.686540  \n",
      "     region    tenure       age  marital   address    income  ed    employ  \\\n",
      "399       3  0.787407  0.072750        1  0.582216 -0.787924   3 -0.308218   \n",
      "7         2  0.130392 -0.496978        0 -0.634309  0.641930   2 -0.077410   \n",
      "905       2 -0.761271  0.398309        0 -0.634309  0.145859   3  0.730421   \n",
      "349       2  0.318111 -0.741148        1 -1.141194  0.145859   4 -0.769836   \n",
      "71        3 -0.902059 -0.171419        0 -0.532932 -0.291852   4 -0.885240   \n",
      "\n",
      "     retire  gender  reside  income_employ_ratio  \n",
      "399     0.0       1       2            -0.771024  \n",
      "7       0.0       0       3             0.054611  \n",
      "905     0.0       0       1            -0.712355  \n",
      "349     0.0       1       6             1.087615  \n",
      "71      0.0       1       1             0.918647  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the IQR method for outlier detection\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Add income_employ_ratio feature\n",
    "data['income_employ_ratio'] = data['income'] / (data['employ'] + 1)\n",
    "\n",
    "# Remove outliers from numerical features using IQR\n",
    "outlier_columns = ['income', 'tenure', 'income_employ_ratio']  # Columns to check for outliers\n",
    "for col in outlier_columns:\n",
    "    data = remove_outliers_iqr(data, col)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['custcat'])\n",
    "y = data['custcat']\n",
    "\n",
    "# Split data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale numerical features to normalize their ranges\n",
    "numerical_features = ['tenure', 'age', 'address', 'income', 'employ', 'income_employ_ratio']  # Include new feature\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "# Ensure categorical variables are not altered by scaling\n",
    "categorical_features = ['region', 'marital', 'gender', 'retire', 'reside']\n",
    "processed_train = X_train.copy()\n",
    "processed_test = X_test.copy()\n",
    "\n",
    "# Verify preprocessing\n",
    "print(processed_train.head())\n",
    "print(processed_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "Accuracy: 0.3803680981595092\n",
      "Confusion Matrix:\n",
      " [[19  3 14  9]\n",
      " [ 8  7 12  9]\n",
      " [12  8 21  5]\n",
      " [10  6  5 15]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.42      0.40        45\n",
      "           2       0.29      0.19      0.23        36\n",
      "           3       0.40      0.46      0.43        46\n",
      "           4       0.39      0.42      0.41        36\n",
      "\n",
      "    accuracy                           0.38       163\n",
      "   macro avg       0.37      0.37      0.37       163\n",
      "weighted avg       0.37      0.38      0.37       163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log_reg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k-Nearest Neighbors Performance:\n",
      "Accuracy: 0.3558282208588957\n",
      "Confusion Matrix:\n",
      " [[25  6 10  4]\n",
      " [13 14  5  4]\n",
      " [15 15 12  4]\n",
      " [14 12  3  7]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.56      0.45        45\n",
      "           2       0.30      0.39      0.34        36\n",
      "           3       0.40      0.26      0.32        46\n",
      "           4       0.37      0.19      0.25        36\n",
      "\n",
      "    accuracy                           0.36       163\n",
      "   macro avg       0.36      0.35      0.34       163\n",
      "weighted avg       0.36      0.36      0.34       163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# k-NN model (default k=5)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(processed_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_knn = knn.predict(processed_test)\n",
    "print(\"\\nk-Nearest Neighbors Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_knn))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 1s 14ms/step - loss: 1.5507 - accuracy: 0.2435 - val_loss: 1.4180 - val_accuracy: 0.2957\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4088 - accuracy: 0.2565 - val_loss: 1.3843 - val_accuracy: 0.2957\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3834 - accuracy: 0.3000 - val_loss: 1.3752 - val_accuracy: 0.2957\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3615 - accuracy: 0.2957 - val_loss: 1.3664 - val_accuracy: 0.2957\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3331 - accuracy: 0.3435 - val_loss: 1.3521 - val_accuracy: 0.2522\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3110 - accuracy: 0.3761 - val_loss: 1.3397 - val_accuracy: 0.2957\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3095 - accuracy: 0.3652 - val_loss: 1.3268 - val_accuracy: 0.3304\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3024 - accuracy: 0.4000 - val_loss: 1.3218 - val_accuracy: 0.3217\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3003 - accuracy: 0.3630 - val_loss: 1.3309 - val_accuracy: 0.2870\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2899 - accuracy: 0.3739 - val_loss: 1.3209 - val_accuracy: 0.3478\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2739 - accuracy: 0.4043 - val_loss: 1.3262 - val_accuracy: 0.3217\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2478 - accuracy: 0.4087 - val_loss: 1.3292 - val_accuracy: 0.3304\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2591 - accuracy: 0.4087 - val_loss: 1.3191 - val_accuracy: 0.3217\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2523 - accuracy: 0.4174 - val_loss: 1.3260 - val_accuracy: 0.3478\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2537 - accuracy: 0.4022 - val_loss: 1.3238 - val_accuracy: 0.3391\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2345 - accuracy: 0.4065 - val_loss: 1.3143 - val_accuracy: 0.3391\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2261 - accuracy: 0.4174 - val_loss: 1.3228 - val_accuracy: 0.3391\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2334 - accuracy: 0.3870 - val_loss: 1.3237 - val_accuracy: 0.3304\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2252 - accuracy: 0.4500 - val_loss: 1.3488 - val_accuracy: 0.2957\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2085 - accuracy: 0.4261 - val_loss: 1.3326 - val_accuracy: 0.3478\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2098 - accuracy: 0.4239 - val_loss: 1.3336 - val_accuracy: 0.3391\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1982 - accuracy: 0.4413 - val_loss: 1.3357 - val_accuracy: 0.3391\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1995 - accuracy: 0.4261 - val_loss: 1.3213 - val_accuracy: 0.3478\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2069 - accuracy: 0.4217 - val_loss: 1.3424 - val_accuracy: 0.3391\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1967 - accuracy: 0.4457 - val_loss: 1.3265 - val_accuracy: 0.3478\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1865 - accuracy: 0.4239 - val_loss: 1.3406 - val_accuracy: 0.3391\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1903 - accuracy: 0.4261 - val_loss: 1.3290 - val_accuracy: 0.3391\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1703 - accuracy: 0.4391 - val_loss: 1.3332 - val_accuracy: 0.3826\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1920 - accuracy: 0.4217 - val_loss: 1.3374 - val_accuracy: 0.3739\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1684 - accuracy: 0.4565 - val_loss: 1.3430 - val_accuracy: 0.3652\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1697 - accuracy: 0.4457 - val_loss: 1.3503 - val_accuracy: 0.3478\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1756 - accuracy: 0.4587 - val_loss: 1.3503 - val_accuracy: 0.3478\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1645 - accuracy: 0.4500 - val_loss: 1.3612 - val_accuracy: 0.3478\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1737 - accuracy: 0.4587 - val_loss: 1.3590 - val_accuracy: 0.3478\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1711 - accuracy: 0.4196 - val_loss: 1.3591 - val_accuracy: 0.3217\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1566 - accuracy: 0.4348 - val_loss: 1.3574 - val_accuracy: 0.3391\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1431 - accuracy: 0.4543 - val_loss: 1.3568 - val_accuracy: 0.3217\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1459 - accuracy: 0.4870 - val_loss: 1.3481 - val_accuracy: 0.3565\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1530 - accuracy: 0.4717 - val_loss: 1.3444 - val_accuracy: 0.3391\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1573 - accuracy: 0.4413 - val_loss: 1.3582 - val_accuracy: 0.3565\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1455 - accuracy: 0.4435 - val_loss: 1.3541 - val_accuracy: 0.3565\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1546 - accuracy: 0.4500 - val_loss: 1.3661 - val_accuracy: 0.3565\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1499 - accuracy: 0.4674 - val_loss: 1.3462 - val_accuracy: 0.3652\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1248 - accuracy: 0.4913 - val_loss: 1.3615 - val_accuracy: 0.3391\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1161 - accuracy: 0.4848 - val_loss: 1.3778 - val_accuracy: 0.3652\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1360 - accuracy: 0.4500 - val_loss: 1.3722 - val_accuracy: 0.3565\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1276 - accuracy: 0.4652 - val_loss: 1.3705 - val_accuracy: 0.3478\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1254 - accuracy: 0.4565 - val_loss: 1.3765 - val_accuracy: 0.3304\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1215 - accuracy: 0.4913 - val_loss: 1.3760 - val_accuracy: 0.3304\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1106 - accuracy: 0.4761 - val_loss: 1.3907 - val_accuracy: 0.3304\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Neural Network Performance:\n",
      "Accuracy: 0.4305555555555556\n",
      "Confusion Matrix:\n",
      " [[24  7  7  3]\n",
      " [ 5 18  5  5]\n",
      " [ 9 12  9 10]\n",
      " [ 7  7  5 11]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.59      0.56        41\n",
      "           1       0.41      0.55      0.47        33\n",
      "           2       0.35      0.23      0.27        40\n",
      "           3       0.38      0.37      0.37        30\n",
      "\n",
      "    accuracy                           0.43       144\n",
      "   macro avg       0.42      0.43      0.42       144\n",
      "weighted avg       0.42      0.43      0.42       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Define the IQR method for outlier detection\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Add income_employ_ratio feature\n",
    "data['income_employ_ratio'] = data['income'] / (data['employ'] + 1)\n",
    "\n",
    "# Remove outliers from numerical features using IQR\n",
    "outlier_columns = ['income', 'tenure', 'income_employ_ratio']\n",
    "for col in outlier_columns:\n",
    "    data = remove_outliers_iqr(data, col)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['custcat'])\n",
    "y = data['custcat']\n",
    "\n",
    "# Shift labels to start from 0 for TensorFlow compatibility\n",
    "y_mapped = y - 1\n",
    "\n",
    "# Split data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train_mapped, y_test_mapped = train_test_split(X, y_mapped, test_size=0.2, random_state=42, stratify=y_mapped)\n",
    "\n",
    "# Scale numerical features to normalize their ranges\n",
    "numerical_features = ['tenure', 'age', 'address', 'income', 'employ', 'income_employ_ratio']\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "# Neural Network architecture\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=X_train.shape[1]),  # First hidden layer\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    Dense(32, activation='relu'),  # Second hidden layer\n",
    "    Dense(4, activation='softmax')  # Output layer (4 classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_mapped, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_nn_probs = model.predict(X_test)\n",
    "y_pred_nn = y_pred_nn_probs.argmax(axis=1)  # Map back to class labels (0-based index for mapped labels)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"\\nNeural Network Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_mapped, y_pred_nn))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_mapped, y_pred_nn))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_mapped, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key Changes**\n",
    "\n",
    "#### **Outlier Removal:**\n",
    "- Handled with the `remove_outliers_iqr` function before splitting the data. This ensures that extreme values do not skew the model's training.\n",
    "\n",
    "#### **Feature Engineering:**\n",
    "- Added a derived feature, `income_employ_ratio`, which provides additional insight by capturing the relationship between income and employment.\n",
    "\n",
    "#### **Adjusted Labels:**\n",
    "- Shifted labels (`y_mapped = y - 1`) to start from `0`, as required by the `sparse_categorical_crossentropy` loss function in TensorFlow.\n",
    "\n",
    "#### **Numerical Scaling:**\n",
    "- Scaled all numerical features, including the newly created `income_employ_ratio`, using `StandardScaler` to ensure uniform ranges and improve model convergence.\n",
    "\n",
    "#### **Neural Network Input:**\n",
    "- Dynamically set the `input_dim` of the first `Dense` layer to match the number of features in `X_train` (`X_train.shape[1]`).\n",
    "\n",
    "#### **Predictions:**\n",
    "- Removed the `+1` adjustment when predicting labels because the model now uses 0-based indices directly (after label adjustment).\n",
    "\n",
    "---\n",
    "\n",
    "### **Output Example**\n",
    "After running the code, youll obtain:\n",
    "\n",
    "#### **Accuracy:**\n",
    "- A metric that measures the overall percentage of correctly classified samples.\n",
    "\n",
    "#### **Confusion Matrix:**\n",
    "- A detailed breakdown of:\n",
    "  - **True Positives (TP):** Correct predictions for a class.\n",
    "  - **False Positives (FP):** Misclassified as a class.\n",
    "  - **True Negatives (TN):** Correctly not classified as a class.\n",
    "  - **False Negatives (FN):** Missed predictions for a class.\n",
    "\n",
    "#### **Classification Report:**\n",
    "- Includes:\n",
    "  - **Precision:** How many of the predicted instances were correct.\n",
    "  - **Recall:** How many actual instances were correctly identified.\n",
    "  - **F1-Score:** The harmonic mean of precision and recall.\n",
    "  - **Support:** The number of actual samples in each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **classification report** generated by `sklearn.metrics.classification_report`. It summarizes the performance of a classification model. Lets break it down:\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Metrics**\n",
    "1. **Accuracy:**  \n",
    "   - **Definition:** The proportion of correctly predicted samples out of the total samples.  \n",
    "   - **In this case:**  \n",
    "     ```\n",
    "     Accuracy = 0.43\n",
    "     ```\n",
    "     This means the model correctly classified 43% of the test samples.\n",
    "\n",
    "2. **Macro Average:**  \n",
    "   - **Definition:** The arithmetic mean of precision, recall, and F1-score across all classes, giving equal weight to each class regardless of its size.  \n",
    "   - **Why it matters:** It provides a balanced view of the model's performance across all classes, even if the dataset is imbalanced.  \n",
    "   - **In this case:**  \n",
    "     ```\n",
    "     Macro Avg = 0.42 (F1-Score)\n",
    "     ```\n",
    "     This means that, on average, the models F1-score (harmonic mean of precision and recall) across all classes is 42%.\n",
    "\n",
    "3. **Weighted Average:**  \n",
    "   - **Definition:** The weighted mean of precision, recall, and F1-score, where the weights are the number of samples in each class.  \n",
    "   - **Why it matters:** It accounts for class imbalances by giving more importance to larger classes.  \n",
    "   - **In this case:**  \n",
    "     ```\n",
    "     Weighted Avg = 0.42 (F1-Score)\n",
    "     ```\n",
    "     This means the overall F1-score is 42%, considering the relative size of each class.\n",
    "\n",
    "4. **Support:**  \n",
    "   - **Definition:** The number of samples in the test set.  \n",
    "   - **In this case:**  \n",
    "     ```\n",
    "     Support = 144\n",
    "     ```\n",
    "     This means the test set contains 144 samples in total.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Does This Tell You About the Model?**\n",
    "1. **Overall Performance:**\n",
    "   - The model has low accuracy (43%), suggesting that it struggles to classify the data correctly.\n",
    "   - Precision, recall, and F1-scores (from macro and weighted averages) are similarly low.\n",
    "\n",
    "2. **Class Balance:**\n",
    "   - If the dataset is imbalanced (some classes are much more frequent than others), the **weighted average** is more informative because it accounts for class size.\n",
    "\n",
    "3. **Actionable Insights:**\n",
    "   - **Feature Engineering:** Consider adding new features or improving the current ones (e.g., more meaningful derived features).\n",
    "   - **Hyperparameter Tuning:** Adjust the architecture or training process (e.g., learning rate, batch size, dropout).\n",
    "   - **Data Augmentation:** Collect more data, especially for underrepresented classes, or apply augmentation techniques.\n",
    "   - **Different Models:** Try alternative models (e.g., Random Forest, Gradient Boosting, etc.) to see if they perform better.\n",
    "\n",
    "---\n",
    "\n",
    "### **What to Do Next?**\n",
    "To improve these metrics, you might:\n",
    "1. Investigate class-specific performance in the detailed report to identify which classes are misclassified more often.\n",
    "2. Check if theres a significant imbalance in class distribution.\n",
    "3. Experiment with the model architecture or additional feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your dataset contains 12 columns, including both numerical and categorical features. Here's a summary of the relevant details:\n",
    "\n",
    "- **Categorical Features**:\n",
    "  - `region` (e.g., regions encoded as integers)\n",
    "  - `marital` (e.g., marital status encoded as 0/1)\n",
    "  - `gender` (e.g., gender encoded as 0/1)\n",
    "  - `reside` (e.g., number of residents in a household, might behave as categorical)\n",
    "\n",
    "- **Numerical Features**:\n",
    "  - `tenure`, `age`, `address`, `income`, `employ`, `retire`.\n",
    "\n",
    "- **Target**:\n",
    "  - `custcat` (target variable with 4 categories: 1, 2, 3, 4).\n",
    "\n",
    "### **Embedding Recommendations**\n",
    "\n",
    "For your categorical variables (`region`, `marital`, `gender`, and potentially `reside`), embeddings can help improve the accuracy of your model by creating meaningful vector representations of these features. Here's how to decide on embedding sizes and configure them:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Suggested Embedding Dimensions**\n",
    "- A general rule for determining the embedding dimension:\n",
    "  \\[\n",
    "  \\text{Embedding Dimension} = \\min(50, \\text{unique values}/2)\n",
    "  \\]\n",
    "  Based on this rule:\n",
    "  - `region` (3 unique values): Embedding size of 2.\n",
    "  - `marital` (2 unique values): Embedding size of 1.\n",
    "  - `gender` (2 unique values): Embedding size of 1.\n",
    "  - `reside` (6 unique values): Embedding size of 3.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Steps to Implement Embeddings**\n",
    "\n",
    "Heres a plan for integrating embeddings into your model:\n",
    "\n",
    "1. **Define Inputs**:\n",
    "   - Include both numerical and categorical inputs.\n",
    "2. **Embedding Layers**:\n",
    "   - Add an embedding layer for each categorical feature.\n",
    "3. **Concatenate Features**:\n",
    "   - Combine embeddings and numerical features into a single tensor.\n",
    "4. **Pass Through Neural Network**:\n",
    "   - Use the combined input in your model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 1s 32ms/step - loss: 1.4097 - accuracy: 0.2391 - val_loss: 1.3821 - val_accuracy: 0.2783\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3666 - accuracy: 0.3522 - val_loss: 1.3587 - val_accuracy: 0.4261\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3453 - accuracy: 0.3717 - val_loss: 1.3505 - val_accuracy: 0.3913\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3316 - accuracy: 0.3739 - val_loss: 1.3475 - val_accuracy: 0.3739\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3208 - accuracy: 0.3870 - val_loss: 1.3453 - val_accuracy: 0.3913\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3123 - accuracy: 0.3804 - val_loss: 1.3451 - val_accuracy: 0.3739\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3026 - accuracy: 0.4022 - val_loss: 1.3441 - val_accuracy: 0.3652\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2944 - accuracy: 0.4043 - val_loss: 1.3448 - val_accuracy: 0.4000\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2853 - accuracy: 0.4130 - val_loss: 1.3464 - val_accuracy: 0.3913\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2788 - accuracy: 0.4196 - val_loss: 1.3397 - val_accuracy: 0.3652\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2705 - accuracy: 0.4261 - val_loss: 1.3378 - val_accuracy: 0.3565\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2661 - accuracy: 0.4196 - val_loss: 1.3379 - val_accuracy: 0.3565\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2580 - accuracy: 0.4326 - val_loss: 1.3479 - val_accuracy: 0.3217\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2538 - accuracy: 0.4239 - val_loss: 1.3379 - val_accuracy: 0.3478\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2461 - accuracy: 0.4457 - val_loss: 1.3522 - val_accuracy: 0.3391\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2399 - accuracy: 0.4609 - val_loss: 1.3529 - val_accuracy: 0.3304\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2337 - accuracy: 0.4543 - val_loss: 1.3512 - val_accuracy: 0.3391\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2285 - accuracy: 0.4457 - val_loss: 1.3474 - val_accuracy: 0.3565\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2221 - accuracy: 0.4696 - val_loss: 1.3555 - val_accuracy: 0.3478\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2199 - accuracy: 0.4674 - val_loss: 1.3681 - val_accuracy: 0.3130\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2109 - accuracy: 0.4717 - val_loss: 1.3617 - val_accuracy: 0.3304\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2046 - accuracy: 0.4891 - val_loss: 1.3661 - val_accuracy: 0.3130\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1977 - accuracy: 0.4826 - val_loss: 1.3656 - val_accuracy: 0.3130\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1917 - accuracy: 0.4870 - val_loss: 1.3777 - val_accuracy: 0.3217\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1863 - accuracy: 0.4978 - val_loss: 1.3784 - val_accuracy: 0.2957\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1829 - accuracy: 0.5065 - val_loss: 1.3866 - val_accuracy: 0.3217\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1750 - accuracy: 0.4978 - val_loss: 1.3775 - val_accuracy: 0.3130\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1699 - accuracy: 0.5152 - val_loss: 1.3930 - val_accuracy: 0.2783\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1610 - accuracy: 0.5174 - val_loss: 1.4033 - val_accuracy: 0.2696\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1547 - accuracy: 0.5304 - val_loss: 1.4066 - val_accuracy: 0.2783\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1493 - accuracy: 0.5348 - val_loss: 1.4088 - val_accuracy: 0.2870\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1405 - accuracy: 0.5543 - val_loss: 1.4196 - val_accuracy: 0.3043\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1335 - accuracy: 0.5435 - val_loss: 1.4221 - val_accuracy: 0.2696\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1282 - accuracy: 0.5457 - val_loss: 1.4430 - val_accuracy: 0.2783\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1268 - accuracy: 0.5370 - val_loss: 1.4301 - val_accuracy: 0.3130\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1213 - accuracy: 0.5500 - val_loss: 1.4498 - val_accuracy: 0.2783\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1064 - accuracy: 0.5652 - val_loss: 1.4338 - val_accuracy: 0.3043\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1007 - accuracy: 0.5717 - val_loss: 1.4557 - val_accuracy: 0.2696\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0976 - accuracy: 0.5652 - val_loss: 1.4549 - val_accuracy: 0.2870\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0862 - accuracy: 0.5783 - val_loss: 1.4628 - val_accuracy: 0.2783\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0826 - accuracy: 0.5913 - val_loss: 1.4643 - val_accuracy: 0.2870\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0742 - accuracy: 0.5957 - val_loss: 1.4783 - val_accuracy: 0.2783\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0701 - accuracy: 0.5891 - val_loss: 1.4788 - val_accuracy: 0.2696\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0653 - accuracy: 0.5957 - val_loss: 1.4931 - val_accuracy: 0.2609\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0570 - accuracy: 0.5913 - val_loss: 1.4965 - val_accuracy: 0.2609\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0512 - accuracy: 0.6087 - val_loss: 1.4952 - val_accuracy: 0.2609\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0429 - accuracy: 0.6087 - val_loss: 1.5150 - val_accuracy: 0.2783\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0400 - accuracy: 0.6065 - val_loss: 1.5068 - val_accuracy: 0.2696\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0312 - accuracy: 0.6196 - val_loss: 1.5189 - val_accuracy: 0.2522\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0232 - accuracy: 0.6261 - val_loss: 1.5174 - val_accuracy: 0.2957\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Neural Network with Embeddings Performance:\n",
      "Accuracy: 0.3541666666666667\n",
      "Confusion Matrix:\n",
      " [[22  6  9  4]\n",
      " [ 6 16  8  3]\n",
      " [ 8 15  8  9]\n",
      " [ 8  7 10  5]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.54      0.52        41\n",
      "           1       0.36      0.48      0.42        33\n",
      "           2       0.23      0.20      0.21        40\n",
      "           3       0.24      0.17      0.20        30\n",
      "\n",
      "    accuracy                           0.35       144\n",
      "   macro avg       0.33      0.35      0.34       144\n",
      "weighted avg       0.34      0.35      0.34       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['region', 'marital', 'gender', 'reside']\n",
    "for col in categorical_features:\n",
    "    data[col] = LabelEncoder().fit_transform(data[col])\n",
    "\n",
    "# Add a feature for income/employ ratio\n",
    "data['income_employ_ratio'] = data['income'] / (data['employ'] + 1)\n",
    "\n",
    "# Split data into features and target\n",
    "X = data.drop(columns=['custcat'])\n",
    "y = data['custcat'] - 1  # Shift labels to start from 0 for TensorFlow compatibility\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['tenure', 'age', 'address', 'income', 'employ', 'income_employ_ratio']\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "# Define embedding dimensions for categorical features\n",
    "embedding_dims = {\n",
    "    'region': 2,\n",
    "    'marital': 1,\n",
    "    'gender': 1,\n",
    "    'reside': 3\n",
    "}\n",
    "\n",
    "# Define TensorFlow inputs for numerical and categorical features\n",
    "numerical_input = Input(shape=(len(numerical_features),), name=\"Numerical_Input\")\n",
    "categorical_inputs = {}\n",
    "embeddings = []\n",
    "\n",
    "# Create embedding layers for each categorical feature\n",
    "for feature, embed_dim in embedding_dims.items():\n",
    "    unique_values = data[feature].nunique()\n",
    "    cat_input = Input(shape=(1,), name=f\"{feature}_Input\")\n",
    "    cat_embedding = Embedding(input_dim=unique_values, output_dim=embed_dim, name=f\"{feature}_Embedding\")(cat_input)\n",
    "    cat_embedding_flattened = Flatten()(cat_embedding)\n",
    "    categorical_inputs[feature] = cat_input\n",
    "    embeddings.append(cat_embedding_flattened)\n",
    "\n",
    "# Combine numerical and categorical features\n",
    "all_inputs = [numerical_input] + list(categorical_inputs.values())\n",
    "concatenated_features = Concatenate()([numerical_input] + embeddings)\n",
    "\n",
    "# Neural network architecture\n",
    "dense_1 = Dense(64, activation='relu')(concatenated_features)\n",
    "dense_2 = Dense(32, activation='relu')(dense_1)\n",
    "output = Dense(4, activation='softmax', name=\"Output\")(dense_2)  # 4 classes\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=all_inputs, outputs=output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Prepare model inputs\n",
    "train_inputs = [X_train[numerical_features]] + [X_train[feature].values for feature in embedding_dims.keys()]\n",
    "test_inputs = [X_test[numerical_features]] + [X_test[feature].values for feature in embedding_dims.keys()]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_inputs, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_probs = model.predict(test_inputs)\n",
    "y_pred = y_pred_probs.argmax(axis=1)\n",
    "\n",
    "# Metrics\n",
    "print(\"Neural Network with Embeddings Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Highlights\n",
    "Embedding Layers:\n",
    "\n",
    "Each categorical feature has its own embedding layer (e.g., region_Embedding).\n",
    "Embedding(input_dim, output_dim), where:\n",
    "input_dim: Number of unique values in the categorical feature.\n",
    "output_dim: Embedding size, tuned based on feature complexity.\n",
    "Numerical Features:\n",
    "\n",
    "Directly fed into the model after scaling using StandardScaler.\n",
    "Model Inputs:\n",
    "\n",
    "A list containing numerical features and embeddings for categorical features is passed to the model.\n",
    "Neural Network:\n",
    "\n",
    "Combines numerical and embedded categorical features into a unified input for dense layers.\n",
    "How to Adjust for Your Dataset\n",
    "Update embedding_dims based on the complexity of each categorical feature.\n",
    "Modify the neural network architecture (e.g., number of layers, units) based on dataset size and complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a functional solution that allows entering the characteristics of a client and returns the group to which it belongs, give me the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 18ms/step - loss: 1.9076 - accuracy: 0.2641 - val_loss: 1.3881 - val_accuracy: 0.2812 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.9006 - accuracy: 0.2438 - val_loss: 1.3797 - val_accuracy: 0.2562 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.7922 - accuracy: 0.2453 - val_loss: 1.3805 - val_accuracy: 0.2750 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.7553 - accuracy: 0.2266 - val_loss: 1.3812 - val_accuracy: 0.2688 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.6526 - accuracy: 0.2484 - val_loss: 1.3799 - val_accuracy: 0.2688 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.6030 - accuracy: 0.2375 - val_loss: 1.3776 - val_accuracy: 0.2937 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.5946 - accuracy: 0.2672 - val_loss: 1.3723 - val_accuracy: 0.2875 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.5810 - accuracy: 0.2469 - val_loss: 1.3690 - val_accuracy: 0.2937 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.5651 - accuracy: 0.2688 - val_loss: 1.3656 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.5257 - accuracy: 0.2906 - val_loss: 1.3653 - val_accuracy: 0.3063 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.5121 - accuracy: 0.2688 - val_loss: 1.3636 - val_accuracy: 0.2688 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.4863 - accuracy: 0.2812 - val_loss: 1.3608 - val_accuracy: 0.2875 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.4539 - accuracy: 0.3172 - val_loss: 1.3588 - val_accuracy: 0.2937 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.4773 - accuracy: 0.2766 - val_loss: 1.3556 - val_accuracy: 0.2875 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.4824 - accuracy: 0.2609 - val_loss: 1.3531 - val_accuracy: 0.2625 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.4879 - accuracy: 0.2719 - val_loss: 1.3530 - val_accuracy: 0.2812 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.4456 - accuracy: 0.2937 - val_loss: 1.3553 - val_accuracy: 0.2937 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.4708 - accuracy: 0.2703 - val_loss: 1.3515 - val_accuracy: 0.2937 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.4202 - accuracy: 0.2922 - val_loss: 1.3485 - val_accuracy: 0.2937 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.4548 - accuracy: 0.2891 - val_loss: 1.3464 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Test Accuracy: 0.2350\n",
      "Model saved to customer_model\\customer_model.h5\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "\n",
      "Prediction Results:\n",
      "Predicted Group: D\n",
      "\n",
      "Probability Breakdown:\n",
      "Group A: 26.51%\n",
      "Group B: 22.98%\n",
      "Group C: 21.74%\n",
      "Group D: 28.77%\n",
      "\n",
      "Confidence: 28.77%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "class CustomerGroupClassifier:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the Customer Group Classifier\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.label_encoder = None\n",
    "        \n",
    "    def prepare_data(self, features, labels):\n",
    "        \"\"\"\n",
    "        Prepare data for model training\n",
    "        \n",
    "        Args:\n",
    "            features (pd.DataFrame): Input features\n",
    "            labels (pd.Series): Target labels\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Processed features and labels\n",
    "        \"\"\"\n",
    "        # Prepare features\n",
    "        # Add derived features if needed\n",
    "        features['income_employ_ratio'] = features['income'] / (features['employ'] + 1)\n",
    "        \n",
    "        # Encode labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        encoded_labels = self.label_encoder.fit_transform(labels)\n",
    "        \n",
    "        # Scale features\n",
    "        self.scaler = StandardScaler()\n",
    "        scaled_features = self.scaler.fit_transform(features)\n",
    "        \n",
    "        return scaled_features, encoded_labels\n",
    "    \n",
    "    def build_model(self, input_shape, num_classes):\n",
    "        \"\"\"\n",
    "        Build neural network model\n",
    "        \n",
    "        Args:\n",
    "            input_shape (int): Number of input features\n",
    "            num_classes (int): Number of output classes\n",
    "        \n",
    "        Returns:\n",
    "            tf.keras.Model: Compiled neural network\n",
    "        \"\"\"\n",
    "        model = Sequential([\n",
    "            Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.3),\n",
    "            \n",
    "            Dense(32, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.3),\n",
    "            \n",
    "            Dense(16, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            \n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_model(self, X, y, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Train the classification model\n",
    "        \n",
    "        Args:\n",
    "            X (pd.DataFrame): Input features\n",
    "            y (pd.Series): Target labels\n",
    "            test_size (float): Proportion of data for testing\n",
    "        \n",
    "        Returns:\n",
    "            float: Test accuracy\n",
    "        \"\"\"\n",
    "        # Prepare data\n",
    "        X_scaled, y_encoded = self.prepare_data(X, y)\n",
    "        \n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, y_encoded, test_size=test_size, stratify=y_encoded, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Determine number of classes\n",
    "        num_classes = len(np.unique(y_encoded))\n",
    "        \n",
    "        # Build model\n",
    "        self.model = self.build_model(X_scaled.shape[1], num_classes)\n",
    "        \n",
    "        # Callbacks\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_accuracy', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.5, \n",
    "            patience=5, \n",
    "            min_lr=1e-5\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=100,\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate the model\n",
    "        test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "        \n",
    "        return test_accuracy\n",
    "    \n",
    "    def save_model(self, model_dir='customer_model'):\n",
    "        \"\"\"\n",
    "        Save trained model, scaler, and label encoder\n",
    "        \n",
    "        Args:\n",
    "            model_dir (str): Directory to save model components\n",
    "        \"\"\"\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        model_path = os.path.join(model_dir, 'customer_model.h5')\n",
    "        self.model.save(model_path)\n",
    "        \n",
    "        # Save scaler\n",
    "        scaler_path = os.path.join(model_dir, 'customer_scaler.joblib')\n",
    "        joblib.dump(self.scaler, scaler_path)\n",
    "        \n",
    "        # Save label encoder\n",
    "        encoder_path = os.path.join(model_dir, 'customer_label_encoder.joblib')\n",
    "        joblib.dump(self.label_encoder, encoder_path)\n",
    "        \n",
    "        print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    def predict_group(self, input_features):\n",
    "        \"\"\"\n",
    "        Predict customer group for given features\n",
    "        \n",
    "        Args:\n",
    "            input_features (dict or pd.DataFrame): Input features\n",
    "        \n",
    "        Returns:\n",
    "            dict: Prediction results\n",
    "        \"\"\"\n",
    "        # Convert input to DataFrame if it's a dictionary\n",
    "        if isinstance(input_features, dict):\n",
    "            input_features = pd.DataFrame([input_features])\n",
    "        \n",
    "        # Add derived features\n",
    "        input_features['income_employ_ratio'] = input_features['income'] / (input_features['employ'] + 1)\n",
    "        \n",
    "        # Scale features\n",
    "        input_scaled = self.scaler.transform(input_features)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        prediction_probs = self.model.predict(input_scaled)[0]\n",
    "        predicted_class_index = np.argmax(prediction_probs)\n",
    "        \n",
    "        # Map back to original labels\n",
    "        predicted_group = self.label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "        \n",
    "        # Prepare results\n",
    "        return {\n",
    "            'predicted_group': predicted_group,\n",
    "            'probabilities': {\n",
    "                f'Group {self.label_encoder.inverse_transform([i])[0]}': float(prob) \n",
    "                for i, prob in enumerate(prediction_probs)\n",
    "            },\n",
    "            'confidence': float(prediction_probs[predicted_class_index])\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    # Example usage with synthetic data\n",
    "    # Replace this with your actual data loading\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Simulate features\n",
    "    n_samples = 1000\n",
    "    features = pd.DataFrame({\n",
    "        'tenure': np.random.randint(1, 60, n_samples),\n",
    "        'age': np.random.randint(18, 80, n_samples),\n",
    "        'address': np.random.randint(1, 20, n_samples),\n",
    "        'income': np.random.randint(20000, 200000, n_samples),\n",
    "        'employ': np.random.randint(1, 40, n_samples)\n",
    "    })\n",
    "    \n",
    "    # Simulate labels (4 customer groups)\n",
    "    labels = pd.Series(np.random.choice(['A', 'B', 'C', 'D'], n_samples))\n",
    "    \n",
    "    # Create and train the model\n",
    "    classifier = CustomerGroupClassifier()\n",
    "    classifier.train_model(features, labels)\n",
    "    \n",
    "    # Save the model\n",
    "    classifier.save_model()\n",
    "    \n",
    "    # Example prediction\n",
    "    sample_client = {\n",
    "        'tenure': 24,\n",
    "        'age': 35,\n",
    "        'address': 10,\n",
    "        'income': 75000,\n",
    "        'employ': 15\n",
    "    }\n",
    "    \n",
    "    # Predict group\n",
    "    prediction = classifier.predict_group(sample_client)\n",
    "    \n",
    "    # Print prediction results\n",
    "    print(\"\\nPrediction Results:\")\n",
    "    print(f\"Predicted Group: {prediction['predicted_group']}\")\n",
    "    print(\"\\nProbability Breakdown:\")\n",
    "    for group, prob in prediction['probabilities'].items():\n",
    "        print(f\"{group}: {prob:.2%}\")\n",
    "    print(f\"\\nConfidence: {prediction['confidence']:.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class_model_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
